{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = utils.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = images.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23e1485b400>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape(28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Base Network For Visual Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X,Y),(x,y) = keras.datasets.mnist.load_data()\n",
    "\n",
    "X = X.reshape(-1,28,28,1) / 255.\n",
    "x = x.reshape(-1,28,28,1) / 255.\n",
    "\n",
    "Y = keras.utils.to_categorical(Y)\n",
    "y = keras.utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1), (60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,x.shape,Y.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_input = Input(shape=(28,28,1))\n",
    "\n",
    "loss_conv = Conv2D(32,3,activation=\"relu\")(loss_input)\n",
    "loss_conv = Conv2D(64,3,activation=\"relu\")(loss_conv)\n",
    "loss_pool = MaxPool2D()(loss_conv)\n",
    "loss_conv = Conv2D(128,2,activation=\"relu\")(loss_pool)\n",
    "loss_enc = BatchNormalization()(loss_conv)\n",
    "loss_flatten = Flatten()(loss_enc)\n",
    "loss_dense = Dense(512,activation=\"relu\")(loss_flatten)\n",
    "loss_out = Dense(10,activation=\"softmax\")(loss_dense)\n",
    "\n",
    "loss_train = keras.Model(loss_input,loss_out)\n",
    "loss_enc = keras.Model(loss_input,loss_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23e77849b70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_train.load_weights(\"weights/models/conv_autoencoder_with_perceptual_loss/loss_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0493 - val_accuracy: 0.9875\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 9s 154us/sample - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.0640 - val_accuracy: 0.9849\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 11s 176us/sample - loss: 0.0078 - accuracy: 0.9977 - val_loss: 0.0589 - val_accuracy: 0.9865\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 12s 192us/sample - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0461 - val_accuracy: 0.9888\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 13s 219us/sample - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.1109 - val_accuracy: 0.9809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23e77d1f5c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_train.fit(X,Y,batch_size=256,epochs=5,validation_data=(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train.save_weights(\"weights/models/conv_autoencoder_with_perceptual_loss/loss_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visual_loss(y_true,y_pred):\n",
    "    y_true = loss_enc(y_true)\n",
    "    y_pred = loss_enc(y_pred)\n",
    "    return keras.losses.mse(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(28,28,1))\n",
    "\n",
    "enc = Conv2D(32,3,activation=\"relu\",padding=\"same\")(inputs)\n",
    "enc = MaxPool2D()(enc)\n",
    "enc = Conv2D(48,3,activation=\"linear\",padding=\"same\")(enc)\n",
    "enc = MaxPool2D()(enc)\n",
    "enc = BatchNormalization()(enc)\n",
    "\n",
    "dense = Flatten()(enc)\n",
    "dense = Dense(512,activation=\"relu\")(dense)\n",
    "encodings = Dense(128,activation=\"linear\")(dense)\n",
    "dense = Dense(512,activation=\"relu\")(encodings)\n",
    "dense = Dense(2352)(dense)\n",
    "dense = Reshape((7,7,48))(dense)\n",
    "\n",
    "dec = UpSampling2D()(dense)\n",
    "dec = Conv2D(48,3,activation=\"linear\",padding=\"same\")(dec)\n",
    "dec = UpSampling2D()(dec)\n",
    "dec = BatchNormalization()(dec)\n",
    "dec = Conv2D(32,3,activation=\"relu\",padding=\"same\")(dec)\n",
    "dec = BatchNormalization()(dec)\n",
    "dec = Conv2D(1,4,activation=\"sigmoid\",padding=\"same\")(dec)\n",
    "\n",
    "model = keras.Model(inputs,dec)\n",
    "encoder = keras.Model(inputs,encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 48)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 48)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 7, 7, 48)          192       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1204736   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               66048     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2352)              1206576   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 7, 7, 48)          0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 14, 14, 48)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 48)        20784     \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 28, 28, 48)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 48)        192       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 32)        13856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 1)         513       \n",
      "=================================================================\n",
      "Total params: 2,592,881\n",
      "Trainable params: 2,592,625\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 14, 14, 48)        13872     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 48)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 7, 7, 48)          192       \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2352)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               1204736   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 128)               65664     \n",
      "=================================================================\n",
      "Total params: 1,284,784\n",
      "Trainable params: 1,284,688\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23e129eda20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"weights/models/conv_autoencoder_with_perceptual_loss/autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=visual_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 70000 samples\n",
      "Epoch 1/2\n",
      "70000/70000 [==============================] - 37s 525us/sample - loss: 0.0058\n",
      "Epoch 2/2\n",
      "70000/70000 [==============================] - 37s 531us/sample - loss: 0.0052\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x248fdff9390>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(images,images,batch_size=1024,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"weights/models/conv_autoencoder_with_perceptual_loss/autoencoder\")\n",
    "encoder.save_weights(\"weights/models/conv_autoencoder_with_perceptual_loss/encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.5, 27.5, 27.5, -0.5)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = images[np.random.randint(images.shape[0])].reshape(28,28)#\n",
    "pred = model.predict(img.reshape(1,28,28,1)).reshape(28,28)\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "axes[0].imshow(img.reshape(28,28))\n",
    "axes[0].set_title(\"Original\") \n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(pred)\n",
    "axes[1].set_title(\"Re Constructed\")\n",
    "axes[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
